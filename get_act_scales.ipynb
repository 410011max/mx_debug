{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "scales = torch.load(\"act_scales/llama2-7b-hf.pt\", map_location='cpu')\n",
    "scales_mx = torch.load(\"act_scales/llama2-7b-hf-mx.pt\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_tokens.input tensor([[11717]])\n",
      "embed_tokens.output tensor([[-0.0012, -0.0200, -0.0037,  ..., -0.0021, -0.0084,  0.0033]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.self_attn.q_proj.input tensor([[-0.0021, -0.0161, -0.0004,  ..., -0.0013, -0.0055,  0.0012]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.self_attn.q_proj.output tensor([[ 0.2021, -1.4727,  2.2148,  ..., -0.0561,  0.1467, -0.4221]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.self_attn.k_proj.input tensor([[-0.0021, -0.0161, -0.0004,  ..., -0.0013, -0.0055,  0.0012]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.self_attn.k_proj.output tensor([[ 0.0972, -0.2131,  0.3342,  ...,  1.1611, -0.2905,  0.1049]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.self_attn.v_proj.input tensor([[-0.0021, -0.0161, -0.0004,  ..., -0.0013, -0.0055,  0.0012]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.self_attn.v_proj.output tensor([[-0.0002, -0.0132,  0.0075,  ...,  0.0022, -0.0047,  0.0071]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.self_attn.rotary_emb.input tensor([[-0.0002, -0.0132,  0.0075,  ..., -0.0061,  0.0044, -0.0088],\n",
      "        [-0.0065, -0.0020,  0.0023,  ..., -0.0017,  0.0006, -0.0120],\n",
      "        [ 0.0031, -0.0038,  0.0057,  ...,  0.0035,  0.0029, -0.0052],\n",
      "        ...,\n",
      "        [ 0.0315,  0.0684, -0.0463,  ..., -0.0099,  0.0166, -0.0657],\n",
      "        [ 0.0060,  0.0025,  0.0017,  ..., -0.0028,  0.0011, -0.0014],\n",
      "        [ 0.0078,  0.0036, -0.0019,  ...,  0.0022, -0.0047,  0.0071]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.self_attn.rotary_emb.output tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], dtype=torch.float16)\n",
      "layers.0.self_attn.o_proj.input tensor([[-0.0002, -0.0132,  0.0075,  ...,  0.0022, -0.0047,  0.0071]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.self_attn.o_proj.output tensor([[ 0.0044,  0.0025,  0.0102,  ..., -0.0026, -0.0075,  0.0057]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.mlp.gate_proj.input tensor([[ 0.0068, -0.0388,  0.0137,  ..., -0.0105, -0.0359,  0.0186]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.mlp.gate_proj.output tensor([[ 1.5125e-01, -1.1414e-01, -9.5248e-05,  ...,  1.9974e-02,\n",
      "          2.5986e-02,  2.3163e-02]], dtype=torch.float16)\n",
      "layers.0.mlp.act_fn.input tensor([[ 1.5125e-01, -1.1414e-01, -9.5248e-05,  ...,  1.9974e-02,\n",
      "          2.5986e-02,  2.3163e-02]], dtype=torch.float16)\n",
      "layers.0.mlp.act_fn.output tensor([[ 8.1360e-02, -5.3802e-02, -4.7624e-05,  ...,  1.0086e-02,\n",
      "          1.3161e-02,  1.1719e-02]], dtype=torch.float16)\n",
      "layers.0.mlp.up_proj.input tensor([[ 0.0068, -0.0388,  0.0137,  ..., -0.0105, -0.0359,  0.0186]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.mlp.up_proj.output tensor([[-0.0926,  0.0172, -0.0916,  ..., -0.0269,  0.0018, -0.2140]],\n",
      "       dtype=torch.float16)\n",
      "layers.0.mlp.down_proj.input tensor([[-7.5340e-03, -9.2268e-04,  4.3511e-06,  ..., -2.7180e-04,\n",
      "          2.4319e-05, -2.5082e-03]], dtype=torch.float16)\n",
      "layers.0.mlp.down_proj.output tensor([[ 0.0090, -0.0070, -0.0136,  ..., -0.0279,  0.0307, -0.0088]],\n",
      "       dtype=torch.float16)\n",
      "{'embed_tokens.input': tensor([[11717]]), 'embed_tokens.output': tensor([[-0.0012, -0.0200, -0.0037,  ..., -0.0021, -0.0084,  0.0033]],\n",
      "       dtype=torch.float16), 'layers.0.self_attn.q_proj.input': tensor([[-0.0021, -0.0161, -0.0004,  ..., -0.0013, -0.0055,  0.0012]],\n",
      "       dtype=torch.float16), 'layers.0.self_attn.q_proj.output': tensor([[ 0.2021, -1.4727,  2.2148,  ..., -0.0561,  0.1467, -0.4221]],\n",
      "       dtype=torch.float16), 'layers.0.self_attn.k_proj.input': tensor([[-0.0021, -0.0161, -0.0004,  ..., -0.0013, -0.0055,  0.0012]],\n",
      "       dtype=torch.float16), 'layers.0.self_attn.k_proj.output': tensor([[ 0.0972, -0.2131,  0.3342,  ...,  1.1611, -0.2905,  0.1049]],\n",
      "       dtype=torch.float16), 'layers.0.self_attn.v_proj.input': tensor([[-0.0021, -0.0161, -0.0004,  ..., -0.0013, -0.0055,  0.0012]],\n",
      "       dtype=torch.float16), 'layers.0.self_attn.v_proj.output': tensor([[-0.0002, -0.0132,  0.0075,  ...,  0.0022, -0.0047,  0.0071]],\n",
      "       dtype=torch.float16), 'layers.0.self_attn.rotary_emb.input': tensor([[-0.0002, -0.0132,  0.0075,  ..., -0.0061,  0.0044, -0.0088],\n",
      "        [-0.0065, -0.0020,  0.0023,  ..., -0.0017,  0.0006, -0.0120],\n",
      "        [ 0.0031, -0.0038,  0.0057,  ...,  0.0035,  0.0029, -0.0052],\n",
      "        ...,\n",
      "        [ 0.0315,  0.0684, -0.0463,  ..., -0.0099,  0.0166, -0.0657],\n",
      "        [ 0.0060,  0.0025,  0.0017,  ..., -0.0028,  0.0011, -0.0014],\n",
      "        [ 0.0078,  0.0036, -0.0019,  ...,  0.0022, -0.0047,  0.0071]],\n",
      "       dtype=torch.float16), 'layers.0.self_attn.rotary_emb.output': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], dtype=torch.float16), 'layers.0.self_attn.o_proj.input': tensor([[-0.0002, -0.0132,  0.0075,  ...,  0.0022, -0.0047,  0.0071]],\n",
      "       dtype=torch.float16), 'layers.0.self_attn.o_proj.output': tensor([[ 0.0044,  0.0025,  0.0102,  ..., -0.0026, -0.0075,  0.0057]],\n",
      "       dtype=torch.float16), 'layers.0.mlp.gate_proj.input': tensor([[ 0.0068, -0.0388,  0.0137,  ..., -0.0105, -0.0359,  0.0186]],\n",
      "       dtype=torch.float16), 'layers.0.mlp.gate_proj.output': tensor([[ 1.5125e-01, -1.1414e-01, -9.5248e-05,  ...,  1.9974e-02,\n",
      "          2.5986e-02,  2.3163e-02]], dtype=torch.float16), 'layers.0.mlp.act_fn.input': tensor([[ 1.5125e-01, -1.1414e-01, -9.5248e-05,  ...,  1.9974e-02,\n",
      "          2.5986e-02,  2.3163e-02]], dtype=torch.float16), 'layers.0.mlp.act_fn.output': tensor([[ 8.1360e-02, -5.3802e-02, -4.7624e-05,  ...,  1.0086e-02,\n",
      "          1.3161e-02,  1.1719e-02]], dtype=torch.float16), 'layers.0.mlp.up_proj.input': tensor([[ 0.0068, -0.0388,  0.0137,  ..., -0.0105, -0.0359,  0.0186]],\n",
      "       dtype=torch.float16), 'layers.0.mlp.up_proj.output': tensor([[-0.0926,  0.0172, -0.0916,  ..., -0.0269,  0.0018, -0.2140]],\n",
      "       dtype=torch.float16), 'layers.0.mlp.down_proj.input': tensor([[-7.5340e-03, -9.2268e-04,  4.3511e-06,  ..., -2.7180e-04,\n",
      "          2.4319e-05, -2.5082e-03]], dtype=torch.float16), 'layers.0.mlp.down_proj.output': tensor([[ 0.0090, -0.0070, -0.0136,  ..., -0.0279,  0.0307, -0.0088]],\n",
      "       dtype=torch.float16)}\n"
     ]
    }
   ],
   "source": [
    "for key in scales.keys():\n",
    "    print(key, scales[key])\n",
    "print(scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_tokens.input tensor([[11717]])\n",
      "embed_tokens.output tensor([[-0.0012, -0.0200, -0.0037,  ..., -0.0021, -0.0084,  0.0033]])\n",
      "layers.0.self_attn.q_proj.input tensor([[-0.0021, -0.0161, -0.0004,  ..., -0.0013, -0.0055,  0.0012]])\n",
      "layers.0.self_attn.q_proj.output tensor([[ 0.1934, -1.4219,  2.1250,  ..., -0.0752,  0.1230, -0.4062]])\n",
      "layers.0.self_attn.k_proj.input tensor([[-0.0021, -0.0161, -0.0004,  ..., -0.0013, -0.0055,  0.0012]])\n",
      "layers.0.self_attn.k_proj.output tensor([[ 0.0977, -0.1523,  0.3262,  ...,  1.0391, -0.2930,  0.1030]])\n",
      "layers.0.self_attn.v_proj.input tensor([[-0.0021, -0.0161, -0.0004,  ..., -0.0013, -0.0055,  0.0012]])\n",
      "layers.0.self_attn.v_proj.output tensor([[-0.0024, -0.0096,  0.0017,  ...,  0.0015, -0.0013,  0.0041]])\n",
      "layers.0.self_attn.rotary_emb.input tensor([[-0.0024, -0.0096,  0.0017,  ..., -0.0074,  0.0048, -0.0119],\n",
      "        [-0.0020, -0.0002, -0.0033,  ...,  0.0019, -0.0054, -0.0090],\n",
      "        [ 0.0015, -0.0018,  0.0059,  ...,  0.0041,  0.0060, -0.0065],\n",
      "        ...,\n",
      "        [ 0.0272,  0.0481, -0.0288,  ..., -0.0054,  0.0171, -0.0557],\n",
      "        [-0.0004, -0.0021,  0.0063,  ..., -0.0065,  0.0038, -0.0043],\n",
      "        [ 0.0044,  0.0016, -0.0065,  ...,  0.0015, -0.0013,  0.0041]])\n",
      "layers.0.self_attn.rotary_emb.output tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]])\n",
      "layers.0.self_attn.o_proj.input tensor([[-0.0020, -0.0078,  0.0015,  ...,  0.0015, -0.0015,  0.0039]])\n",
      "layers.0.self_attn.o_proj.output tensor([[-0.0020,  0.0003,  0.0121,  ..., -0.0019, -0.0066,  0.0074]])\n",
      "layers.0.mlp.gate_proj.input tensor([[-0.0073, -0.0469,  0.0192,  ..., -0.0096, -0.0364,  0.0237]])\n",
      "layers.0.mlp.gate_proj.output tensor([[ 0.0903, -0.0977, -0.0038,  ...,  0.0273,  0.0283,  0.0035]])\n",
      "layers.0.mlp.act_fn.input tensor([[ 0.0903, -0.0977, -0.0038,  ...,  0.0273,  0.0283,  0.0035]])\n",
      "layers.0.mlp.act_fn.output tensor([[ 0.0474, -0.0464, -0.0019,  ...,  0.0139,  0.0144,  0.0018]])\n",
      "layers.0.mlp.up_proj.input tensor([[-0.0073, -0.0469,  0.0192,  ..., -0.0096, -0.0364,  0.0237]])\n",
      "layers.0.mlp.up_proj.output tensor([[-0.0728, -0.0195, -0.0708,  ..., -0.0115,  0.0337, -0.1533]])\n",
      "layers.0.mlp.down_proj.input tensor([[-0.0034,  0.0009,  0.0001,  ..., -0.0002,  0.0005, -0.0003]])\n",
      "layers.0.mlp.down_proj.output tensor([[ 0.0139, -0.0023, -0.0199,  ..., -0.0238,  0.0229, -0.0070]])\n",
      "{'embed_tokens.input': tensor([[11717]]), 'embed_tokens.output': tensor([[-0.0012, -0.0200, -0.0037,  ..., -0.0021, -0.0084,  0.0033]]), 'layers.0.self_attn.q_proj.input': tensor([[-0.0021, -0.0161, -0.0004,  ..., -0.0013, -0.0055,  0.0012]]), 'layers.0.self_attn.q_proj.output': tensor([[ 0.1934, -1.4219,  2.1250,  ..., -0.0752,  0.1230, -0.4062]]), 'layers.0.self_attn.k_proj.input': tensor([[-0.0021, -0.0161, -0.0004,  ..., -0.0013, -0.0055,  0.0012]]), 'layers.0.self_attn.k_proj.output': tensor([[ 0.0977, -0.1523,  0.3262,  ...,  1.0391, -0.2930,  0.1030]]), 'layers.0.self_attn.v_proj.input': tensor([[-0.0021, -0.0161, -0.0004,  ..., -0.0013, -0.0055,  0.0012]]), 'layers.0.self_attn.v_proj.output': tensor([[-0.0024, -0.0096,  0.0017,  ...,  0.0015, -0.0013,  0.0041]]), 'layers.0.self_attn.rotary_emb.input': tensor([[-0.0024, -0.0096,  0.0017,  ..., -0.0074,  0.0048, -0.0119],\n",
      "        [-0.0020, -0.0002, -0.0033,  ...,  0.0019, -0.0054, -0.0090],\n",
      "        [ 0.0015, -0.0018,  0.0059,  ...,  0.0041,  0.0060, -0.0065],\n",
      "        ...,\n",
      "        [ 0.0272,  0.0481, -0.0288,  ..., -0.0054,  0.0171, -0.0557],\n",
      "        [-0.0004, -0.0021,  0.0063,  ..., -0.0065,  0.0038, -0.0043],\n",
      "        [ 0.0044,  0.0016, -0.0065,  ...,  0.0015, -0.0013,  0.0041]]), 'layers.0.self_attn.rotary_emb.output': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]]), 'layers.0.self_attn.o_proj.input': tensor([[-0.0020, -0.0078,  0.0015,  ...,  0.0015, -0.0015,  0.0039]]), 'layers.0.self_attn.o_proj.output': tensor([[-0.0020,  0.0003,  0.0121,  ..., -0.0019, -0.0066,  0.0074]]), 'layers.0.mlp.gate_proj.input': tensor([[-0.0073, -0.0469,  0.0192,  ..., -0.0096, -0.0364,  0.0237]]), 'layers.0.mlp.gate_proj.output': tensor([[ 0.0903, -0.0977, -0.0038,  ...,  0.0273,  0.0283,  0.0035]]), 'layers.0.mlp.act_fn.input': tensor([[ 0.0903, -0.0977, -0.0038,  ...,  0.0273,  0.0283,  0.0035]]), 'layers.0.mlp.act_fn.output': tensor([[ 0.0474, -0.0464, -0.0019,  ...,  0.0139,  0.0144,  0.0018]]), 'layers.0.mlp.up_proj.input': tensor([[-0.0073, -0.0469,  0.0192,  ..., -0.0096, -0.0364,  0.0237]]), 'layers.0.mlp.up_proj.output': tensor([[-0.0728, -0.0195, -0.0708,  ..., -0.0115,  0.0337, -0.1533]]), 'layers.0.mlp.down_proj.input': tensor([[-0.0034,  0.0009,  0.0001,  ..., -0.0002,  0.0005, -0.0003]]), 'layers.0.mlp.down_proj.output': tensor([[ 0.0139, -0.0023, -0.0199,  ..., -0.0238,  0.0229, -0.0070]])}\n"
     ]
    }
   ],
   "source": [
    "for key in scales_mx.keys():\n",
    "    print(key, scales_mx[key])\n",
    "print(scales_mx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
